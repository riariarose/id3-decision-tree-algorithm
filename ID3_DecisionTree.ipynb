{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSC535 - Data Mining\n",
    "HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Part 1: Implement the ID3 decision tree induciton algorithm \n",
    "\n",
    "#create ID3 fucntion\n",
    "'''def ID3(data, label):\n",
    "input parameters: data, label\n",
    "creates a rootNode\n",
    "creates a tree\n",
    "returns: tree\n",
    "'''\n",
    "def ID3(data, label):\n",
    "    rootNode = getRootNode(data, label)\n",
    "    tree = (rootNode, getAttribute(data, label, rootNode))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getAttribute(data, label, rootNode):\n",
    "    gets a list of attributes under each attribute and recursively creates a sub tree\n",
    "    input parameters: data, label, rootnode\n",
    "    returns: a dictionary list of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def getAttribute(data, label, rootNode):\n",
    "gets a list of attributes under each attribute and recursively creates a sub tree\n",
    "input parameters: data, label, rootnode\n",
    "returns: a dictionary list of attributes\n",
    "'''\n",
    "def getAttribute(data, label, rootNode):\n",
    "    tree = {}\n",
    "    uniqueValues = data[rootNode].unique()\n",
    "    defaultData = data[label].value_counts().idxmax()\n",
    "    tree.update({'default': defaultData})\n",
    "    for uniqueValue in uniqueValues:\n",
    "        dataf = data[data[rootNode] == uniqueValue]\n",
    "        info = calcInfo(dataf[label])\n",
    "        if info > 0:\n",
    "            dataf = dataf.drop([rootNode], axis=1)\n",
    "            nodeA = getRootNode(dataf, label)\n",
    "            tupl = (nodeA, getAttribute(dataf, label, nodeA))\n",
    "            tree.update({str(uniqueValue): tupl})\n",
    "        else:\n",
    "            d = dataf.filter(items=[label, rootNode]).values[0]\n",
    "            key = str(d[1])\n",
    "            value = d[0]\n",
    "            tree.update({key: value})\n",
    "    return dict(OrderedDict(sorted(tree.items(), key=lambda d: d[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def getRootNode(data, label):\n",
    "gets root node for spec attribute list\n",
    "returns: root node\n",
    "'''\n",
    "def getRootNode(data, label):\n",
    "    gainDict = dict()\n",
    "    info = calcInfo(data[label])\n",
    "    if info > 0:\n",
    "        for key in data.keys():\n",
    "            if key != label:\n",
    "                dataf = data.filter(items=[label, key])\n",
    "                gainDict.update({key: calcGain(dataf, key, label, info)})\n",
    "    root = max(gainDict.keys(), key=(lambda x: gainDict[x]))\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def calcGain(data, key, label, iTotal):\n",
    "    calculates information gain value for speciric node\n",
    "'''\n",
    "\n",
    "def calcGain(data, key, label, iTotal):\n",
    "    data = pd.DataFrame(data=data)\n",
    "    entropyTotal = 0.0\n",
    "    uniqueValues = data[key].unique()\n",
    "    for value in uniqueValues:\n",
    "        dataf = data[data[key] == value]\n",
    "        infoValue = calcInfo(data[label])\n",
    "        entropyValue = calcEntropy(s=len(dataf), totalS=len(data), info=infoValue)\n",
    "        entropyTotal += entropyValue\n",
    "    return float(format((iTotal - entropyTotal), '.5f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def calcEntropy(s, totalS, info):\n",
    "calculates entropy value for specific node\n",
    "'''\n",
    "def calcEntropy(s, totalS, info):\n",
    "    s = abs(s)\n",
    "    totalS = abs(totalS)\n",
    "    if s != 0 and totalS != 0:\n",
    "        result = (s / totalS) * info\n",
    "    else:\n",
    "        result = 0\n",
    "    return float(format(result, '.5f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def calcInfo(data):\n",
    "    calculations information value for specific noe\n",
    "'''\n",
    "def calcInfo(data):\n",
    "    info = 0.0\n",
    "    uniqueValues = data.value_counts()\n",
    "    for count in uniqueValues:\n",
    "        p = calcProbability(count, len(data))\n",
    "        if p != 0:\n",
    "            temp1 = p * (log(p, 2))\n",
    "        else:\n",
    "            temp1 = 0\n",
    "        info -= temp1\n",
    "    return float(format(info, '.5f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def calcProbability(s1, s):\n",
    "calculates probability\n",
    "'''\n",
    "\n",
    "def calcProbability(s1, s):\n",
    "    s1 = abs(s1)\n",
    "    s = abs(s)\n",
    "    if s1 != 0 and s != 0:\n",
    "        result = s1 / s\n",
    "    else:\n",
    "        result = 0\n",
    "    return float(format(result, '.5f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''classifies input from decision tree and returns class value\n",
    "'''\n",
    "def classify(data, input):\n",
    "    if isinstance(data, tuple):\n",
    "        if data[0] in input:\n",
    "            attributeData = input[data[0]]\n",
    "            if attributeData in data[1]:\n",
    "                value = data[1].get(attributeData)\n",
    "                result = classify(value, input)\n",
    "            else:\n",
    "                value = data[1].get('default')\n",
    "                result = classify(value, input)\n",
    "        else:\n",
    "            value = data[1].get('default')\n",
    "            result = classify(value, input)\n",
    "    else:\n",
    "        result = data\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' creates dataframe called data2 for training data and class label\n",
    "'''\n",
    "def dataPreprocesing(data, label):\n",
    "    dicList = list()\n",
    "    for row in data:\n",
    "        temp = {label: bool(row[1])}\n",
    "        row[0].update(temp)\n",
    "        dicList.append(row[0])\n",
    "    data2 = pd.DataFrame(data=dicList)\n",
    "    \n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gives the user the ability to read in a file if needed'''\n",
    "def readDataset(filename):\n",
    "    dataframe = pd.read_table(filename, sep=',')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT= \n",
      " ('level', {'Junior': ('lang', {'Python': ('tweets', {'default': True, 'no': ('phd', {'default': False, 'no': True, 'yes': False}), 'yes': True}), 'R': ('tweets', {'default': False, 'yes': ('phd', {'default': False, 'no': True, 'yes': False})}), 'default': True}), 'Mid': True, 'Senior': ('lang', {'Java': False, 'Python': ('tweets', {'default': False, 'no': False, 'yes': True}), 'R': True, 'default': False}), 'default': True}) \n",
      "\n",
      "Classify1 = {'level': 'Junior', 'lang': 'Java', 'tweets': 'yes', 'phd': 'no'} : True\n",
      "Classify2 = {'level': 'Junior', 'lang': 'Java', 'tweets': 'yes', 'phd': 'yes'} : True\n",
      "Classify3 = {'level': 'Intern'} : True\n",
      "Classify4 = {'level': 'Senior'} : False\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'no'}, False),\n",
    "    ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'yes'}, False),\n",
    "    ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, False),\n",
    "    ({'level': 'Mid', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Senior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, False),\n",
    "    ({'level': 'Senior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Senior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Mid', 'lang': 'Java', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, False)\n",
    "]\n",
    "\n",
    "label = 'hired'\n",
    "dataf = dataPreprocesing(training_data, label)\n",
    "dt = ID3(dataf, label)\n",
    "\n",
    "print('DT= \\n', dt, '\\n')\n",
    "c1 = {\"level\": \"Junior\", \"lang\": \"Java\", \"tweets\": \"yes\", \"phd\": \"no\"}\n",
    "c2 = {\"level\": \"Junior\", \"lang\": \"Java\", \"tweets\": \"yes\", \"phd\": \"yes\"}\n",
    "c3 = {\"level\": \"Intern\"}\n",
    "c4 = {\"level\": \"Senior\"}\n",
    "c1_result = classify(dt, c1)\n",
    "c2_result =classify(dt, c2)\n",
    "c3_result =classify(dt, c3)\n",
    "c4_result =classify(dt, c4)\n",
    "print(\"Classify1 =\", c1,\":\", c1_result)\n",
    "print(\"Classify2 =\", c2,\":\", c2_result)\n",
    "print(\"Classify3 =\", c3,\":\", c3_result)\n",
    "print(\"Classify4 =\", c4 ,\":\", c4_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-131a9b7ad916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'result'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'result'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdataf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataPreprocesing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mdt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-bb1f40d2473a>\u001b[0m in \u001b[0;36mdataPreprocesing\u001b[1;34m(data, label)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdicList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdicList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "#Part 2: Find a real data set. Build a DT model for this data set and test your model. \n",
    "#Section 2\n",
    "#data source: https://www.kaggle.com/fireballbyedimyrnmom/us-counties-covid-19-dataset/version/290\n",
    "#my csv file for this dataset was too large. I had to edit it and try to port it in. It did not work, so I \n",
    "#created my own training_data set for this. This section does not work.\n",
    "\n",
    "training_data1 = [\n",
    "    ({'date': '1/21/2020', 'county': 'Snohomish', 'state': 'Washington', 'fips': '53061', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/22/2020', 'county': 'Snohomish', 'state': 'Washington', 'fips': '53061', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/23/2020', 'county': 'Snohomish', 'state': 'Washington', 'fips': '53061', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/24/2020', 'county': 'Cook', 'state': 'Illinois', 'fips': '17031', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/24/2020', 'county': 'Snohomish', 'state': 'Washington', 'fips': '53061', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/25/2020', 'county': 'Orange', 'state': 'Califrornia', 'fips': '6059', 'cases': '1', 'deaths':'1'}),\n",
    "    ({'date': '1/25/2020', 'county': 'Snohomish', 'state': 'Washington', 'fips': '53061', 'cases': '1', 'deaths':'1'}),\n",
    "]\n",
    "label = 'result'\n",
    "label = 'result'\n",
    "dataf = dataPreprocesing(training_data1, label)\n",
    "dt1 = ID3(training_data1, label)\n",
    "\n",
    "\n",
    "print('DT= \\n', dt1, '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ba962433ce634cde499a2def155867a3065a4841db75053b162653b9c20e813"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
